{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 3 (90 pts)\n",
    "\n",
    "## Important note: the template for your solution filename is Name_Surname_PS3.ipynb\n",
    "\n",
    "### The correct answer to the bonus question can be used as an additional reason to increase the final grade in the border case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (25 pts)\n",
    "\n",
    "- (5 pts) Prove that $\\mathrm{vec}(AXB) = (B^\\top \\otimes A)\\, \\mathrm{vec}(X)$ if $\\mathrm{vec}(X)$ is a columnwise reshape of a matrix into a long vector. What does it change if the reshape is rowwise? \n",
    "\n",
    "**Note:** To make a columnwise reshape in Python one should use ```np.reshape(X, order='f')```, where the string ```'f'``` stands for the Fortran ordering. \n",
    "\n",
    "- (2 pts) What is the complexity of a naive computation of $(A \\otimes B) x$? Show how it can be reduced.\n",
    "\n",
    "- (3 pts) Let matrices $A$ and $B$ have eigendecompositions $A = S_A\\Lambda_A S_A^{-1}$ and $B = S_B\\Lambda_B S^{-1}_B$. Find eigenvectors and eigenvalues of the matrix $A\\otimes I + I \\otimes B$, where dimension of $I$ coincides with the dimension of $A$ and $B$.\n",
    "\n",
    "\n",
    "- (10 pts) Let $A = \\mathrm{diag}\\left(\\frac{1}{1000},\\frac{2}{1000},\\dots \\frac{999}{1000}, 1, 1000 \\right)$. Estimate analytically the number of iterations required  to solve linear system with $A$ with the relative accuracy $10^{-4}$ using\n",
    "    - Richardson iteration with the optimal choice of parameter (use $2$-norm)\n",
    "    - Chebyshev iteration (use $2$-norm)\n",
    "    - Conjugate gradient method (use $A$-norm).\n",
    "    \n",
    "- (5 pts) Provide numerical confirmation of your estimate from theoretical point of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dh0nKsm46hpo"
   },
   "source": [
    "## Problem 2 (65 pts)\n",
    "### On the performance of conjugate gradient method for BTTB matrices.\n",
    "\n",
    "You are given 2D image (QR-code) and convolution operator $T$. The application of $T$ results in smoothing of the image. In exact arithmetic, the proposed $T$ is non-singular. However, it becomes rather ill-conditioned with increasing $N$ in finite precision arithmetic. In this task you need to study how the conjugate gradient method performs in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gi5DJJz6hps"
   },
   "source": [
    "The original passcode is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mxPusfbx6hps",
    "outputId": "2fe5ac3f-c23e-4f3d-dc69-b211ec69506b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 329.5, 329.5, -0.5)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = plt.imread('qrcode.gif')[:,:,0]\n",
    "n = x.shape[0]\n",
    "plt.imshow(x, cmap=\"gray\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHzqVBAK6hpu"
   },
   "source": [
    "Blurring can be performed by convolving $n\\times n$ QR-code with the following filter:\n",
    "\n",
    "$$T_{i_1j_1,i_2j_2} = T_{i_1-j_1,i_2-j_2} = \\frac{\\alpha}{\\pi}e^{-\\alpha[(i_1-i_2)^2 + (j_1-j_2)^2]}, \\quad i_1,j_1,i_2,j_2 = 1 \\ldots n, \\quad 1 > \\alpha > 0.$$\n",
    "\n",
    "You know from lectures that this convolution can be viewed as a matrix-vector multiplication of some BTTB matrix $T$ of size $n^2 \\times n^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQSQVkG86hpu"
   },
   "source": [
    "## Task 1 (15 pts) \n",
    "\n",
    "- Write function `T_matvec()` that performs multiplication of $T$ by a given vector $x$ efficiently. Remember about FFT.\n",
    "- Use `scipy.sparse.linalg.LinearOperator` to create an object that has attribute `.dot()` (this object will be further used in the iterative process). Note that `.dot()` input and output must be 1D vectors, so do not forget to use reshape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKiL6Iky6hpv"
   },
   "outputs": [],
   "source": [
    "def T_matvec(x, aplha):\n",
    "    pass\n",
    "\n",
    "# T = spla.LinearOperator((n**2, n**2), matvec = lambda x : T_matvec(x, alpha))\n",
    "# your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vpj3Llkc6hpv"
   },
   "source": [
    "**Remark.** The obtained matrix $T$ is positive definite (at least in the exact arithmetic), hence the conjugate gradient method can be applied to solve with $T$.\n",
    "\n",
    "**Bonus question: Prove the remark above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyoFYerG6hpw"
   },
   "source": [
    "## Task 2 (10 pts) \n",
    "- For $\\alpha \\in \\{ 0.1, 0.01,0.001\\}$ compute $y=Tx$ and deconvolve $x$ using `scipy.sparse.linalg.cg` with $tol \\in \\{10^{-3}, 10^{-4}, 10^{-5}, 10^{-6}, 10^{-7}\\}$. For each pair $\\alpha$, $tol$ write out `num_iters` and relative error $e = \\frac{\\|x - x^*\\|_2}{\\|x\\|_2}$ .\n",
    "- Comment on the results: \n",
    "\n",
    "    1) why the relative error does not converge to zero? \n",
    "    \n",
    "    2) why the relative error converges to different values for different $\\alpha$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZziAoPv6hpw"
   },
   "outputs": [],
   "source": [
    "# your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJ4XOLfw6hpx"
   },
   "source": [
    "In all further tasks fix $\\alpha = 0.01$. Compute $y = Tx$, and add vector with Gaussian noise from $\\mathcal{N}(0, 1)$ to $y$ and get the final right-hand side $\\hat{y}$.\n",
    "\n",
    "## Task 3 (10 pts)\n",
    "- Try to deconvolve $\\hat{y}$ with matrix $T$ using $tol=10^{-5}$ in CG. Explain, why CG does not converge.\n",
    "- Suggest how CG can still be used to recover $x$. What are drawbacks of the suggested approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JzT0Wfzl6hpx"
   },
   "outputs": [],
   "source": [
    "# your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ez3m0Y-n6hpy"
   },
   "source": [
    "## Task 4 (10 pts)\n",
    "\n",
    "- Implement Tikhonov regularization, i.e. deconvolve $\\hat{y}$ with the perturbed matrix $T_{\\lambda} = T + \\lambda^2I$ instead of $T$. Modify `T_matvec()` according to the template below.\n",
    "- Perform computations for all $\\lambda \\in \\{10, 1, 0.1\\}$ and $tol \\in \\{10^{-3}, 10^{-4}, 10^{-5},10^{-6}, 10^{-7} \\}$. For each pair $(\\lambda, tol)$ write out `num_iters` and relative error $e = \\frac{\\|x - x^*\\|_2}{\\|x\\|_2}$. Comment on the results: \n",
    "    - Compare robustness of the convergence with task 2. What the observed results indicate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIs9QI7R6hpy"
   },
   "outputs": [],
   "source": [
    "def T_lmbda_matvec(x, aplha, lmbda):\n",
    "    pass\n",
    "\n",
    "# your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ut0QG1AW6hpy"
   },
   "source": [
    "## Task 5 (20 pts)\n",
    "\n",
    "- Implement BCCB preconditioner for $T_{\\lambda}$ based on Strang preconditioner for Toeplitz matrix (hint: build circulants using first columns of Toeplitz matrices on both levels). You know from lectures that circulants can be explicitly inverted using convolution theorem. Implement the corresponding matvec according to the template provided below.\n",
    "- Check speedup in iterations and runtime that can be gained from the preconditioning for $\\alpha = 0.01$, $\\lambda = 1$ compared with Task 4. Explain results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiJcm6XQ6hpz"
   },
   "outputs": [],
   "source": [
    "def C_inv_matvec(x, alpha, lmbda):\n",
    "    pass\n",
    "\n",
    "# your code is here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
